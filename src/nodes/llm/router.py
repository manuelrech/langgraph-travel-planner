from .base import LLMNode
from ...states.state import State

from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from typing import Literal, Optional

AGENTS = {
    'Planner': 'This agent should be called if the feedback says that the user wants to modify the plan(s).',
    'Finalizer': 'This agent should be called if the feedback says that the user choose a plan.'
}
class RouterResponse(BaseModel):
    agent: Literal[*AGENTS.keys()] # type: ignore
    preferred_plan: Optional[Literal['plan_a', 'plan_b']] = Field(description="The plan that the user prefers, only if the agent is the Finalizer")

prompt_template = PromptTemplate.from_template(
    "You are a router following a human feedback about a plan generated by a set of agents to plan a trip."
    "You need to decide which agent to call next."
    "You can have these possible agents to follow: {agents}"
    "The user input is: {user_input}\n"
    "The user feedback about the plan is: {feedback}"
)

class Router(LLMNode):
    def invoke(self, state: State) -> dict:
        prompt = prompt_template.partial(agents=AGENTS)
        chain = prompt | self.llm.with_structured_output(RouterResponse)
        res: RouterResponse = chain.invoke(
            {
                "user_input": state.enriched_user_input,
                "feedback": state.human_feedback
            }
        )
        return {
            "next_agent": res.agent,
            "preferred_plan": res.preferred_plan
        }
